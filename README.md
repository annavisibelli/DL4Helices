# A deep attention network for predicting amino acid signals in the formation of alpha-helices

This rep contains the code to reproduce the experiments described in the paper "A deep attention network for predicting amino acid signals in the formation of alpha-helices".

# Requirements

This project is entirely build with Python (version>=3.3). The required Python modules are:

* Pandas
* Numpy
* Scikit-learn
* Keras
* Tensorflow
* Gensim
* Matplotlib
* Os
* Sys

# Project Structure

The three main protein classes have been downloaded (mainly alpha, mainly beta, and alpha beta proteins) from the CATH Database (http://www.cathdb.info/browse/tree). The extraction of sequences and secondary structure information from every PDB entry was generated by the Kabsch and Sander DSSP algorithm (https://swift.cmbi.ru.nl/gv/dssp/DSSP_3.html).
From the DSSP output, we were able to extract all the helices present in proteins. To ensure that each helix includes at least two turns, helices shorter than eight residues were discarded. Since signals that trigger the helix formation can also be located outside the helix sequence itself, we analyzed the first and the last four aminoacids inside the helix, taking into account also two or three amino acids before and after each helix. We labeled the sequences with two or three external residues with the suffix 2H or 3H, respectively. **Data** folder contains **3H.csv** and **2H.csv** files.

**Residue_propensity.py** evaluate the residue propensity value for each amino acid in the positions shown in
Fig. 1.


The pssp_lstm module contains an implementation of the MLP specified in Sonderby & Winther, 2015. See the README in that folder for more details and a user guide.

The lm_pretrain module allows users to train bidirectional language models that can be combined with bidirectional RNNs for protein secondary structure prediction. See the README in that folder for more details and a user guide.
